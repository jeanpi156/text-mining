The original idea for the project was to obtain reviews from any movie in IMDB and and conduct two types of analysis.  The first was to use natural language processing, in specific sentiment analysis to gauge what the overall sentiment of the critics was towards the movie, I wanted to see if the movie had been successfull on a level other than a 10 star rating.  Hopefully, by conducting this analysis I could see whether their thoughts on the film on a more complex scale.  The second analysis was the one that would give us some interesting feedback, as it centered around finding the reasons or at least "keywords" that were common amongst reviewers.  This simple frequency analysis combined with the natural language processing would hopefully give insight into why the movie in question was successfull or not.  However, some issues arrived while using IMDB as a data source which made it nearly impossible to have the code work for every movie on the sight on a whim as searching for a movie ID became complicated.  This meant that I had to narrow in on one specific movie, as it would eliminate having to look through a selection of movies to find a code for each.  I chose to analyze "The Matrix Ressurection" as it was a movie that had much anticipation but dissapointed fans of the franchise.

Although the value of the project came from the insight to be gained from the analysis, a large part of the work was spent pre-processing the data in order to be optimal for analysis.  I planned to use the Natural Language Toolkit (NLTK) and some of its libraries to conduct sentiment analysis.  while doing research on the program, i found that NLTK's Sentiment Intensity Analyzer works best on short, individual statements than on long paragraphs.  It was because of this that a majority of the focus was on converting the list of lists of dictionaries that cantained all of the information in every review to individual sentences that could be analyzed.  The textual content of each review was obtained and then separated into individual sentences and evetually words.  These sentences were used as inputs for the sentiment analysis which returned a dictionary of scores that added to 1.  One can see these scores as a gauge of how positive, negative, neutral and compound each sentence was.

The problem with this output is that each "score" only applies to one sentence in one review, which makes it difficult to understand what the general sentiment towards the movie really is.  I then decided to calculate an average score for every category and convert each to a percentage of the total average rating since the sum of all averages did not add up to 1.  The purpose of this was to calculate what would be the average score of all reviews.  The reviews were also broken into words to gauge what the most popular words were across all reviews.  Additionally, each review was stripped of stopwords in order to avoid counting words with little to no meaning.


After doing the sentiment analysis I found that an average score for a review was:
    'pos': 0.09, 'neg': 0.15, 'neu': 0.85, 'compound': -0.09
This means that the average sentiment regarding "The Matrix Ressurection" was largely neutral, but it did lean towards a negative sentiment.  Additionally, I fount it interesting that "good" was the 26th most used word with 245 appearances in the distribution of reviews and the movie still had negative leaning ratings.  Something that was surprising is that the even with all the pre-processing of the data, the top 25 most used words in the distribution have no emotional value.  Words such as "the", "and", "to", etc. all dominated the majority of reviews.  It is surprising to me that one must look to the lesser used words in order to gauge what the sentiment was, as emotional words like "nonesense", which was only used 56 times, are less likely to be common.

I believe that a lot of the negative portion of the scores was heavily influenced by strong words such as "poorly" that was used 27 times accross all reviews we gathered.  "mess" was also a word that was used a lot to describe the film being repeated 79 times. 

I believe that there were many innefficiencies that plagued this project for me.  For instance, I was not familiar with the NLTK libraries and discovering each one and its inner workings took a lot of time from me, as I had to figure out how to correctly gather and process data in order to be able to use it as an input.  That being said, this project showed me the value that documentation holds and how to read it efficiently. Although I had to change the scope of my project due to an issue with IMDB, I enjoyed the challenge of text analysis.  It is quite dissapointing that my analysis did not have as much insight as I had initially hoped, as I wanted this project to serve as a base for movie producers to analyze where they went wrong/ what they did correctly in their last project.  In the end this project helped me gain confidence in gathering and organizing data.